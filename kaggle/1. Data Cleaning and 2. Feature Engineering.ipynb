{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Kaggle dataset is about customer conversion on Google's Google Merchandise Store (also known as GStore, where Google swag is sold). The main purpose of this analysis is to predict revenue per customer and make recommandations on promotional strategies. The main technical challenge it poses to predicting revenue is the presence of multiple high cardinality categorical features. By careful data exploration followed by well-thought choice of feature treatments as well as machine learning algorithm, I show that an optimal solution based on feature-engineering and extreme gradient-boosted decision trees yields an enhanced predictive power of 0.997, as measured by the area under the precision-recall curve. Crucially, these results were obtained without artificial balancing of the data making this approach suitable to real-world applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='top'></a>\n",
    "#### Outline: \n",
    "#### 0. <a href='#Sampling'>Random sampling of training set</a>\n",
    "\n",
    "\n",
    "#### 1. <a href='#clean'>Data Cleaning</a>\n",
    "11. <a href='#cleanID'>Cleaning of IDs</a>\n",
    "12. <a href='#cleanTotals'>Cleaning of Variable Totals</a>\n",
    "13. <a href='#cleanTS'>Cleaning of Time Series Variables</a>\n",
    "14. <a href='#cleanLoc'>Cleaning of Location Variables</a>\n",
    "15. <a href='#cleanDev'>Cleaning of Device Variables</a>\n",
    "16. <a href='#cleanCust'>Cleaning of Custom Dimension Variables</a>\n",
    "\n",
    "\n",
    "#### 2. <a href='#feature-eng'>Feature Engineering</a>\n",
    "21. <a href='#dropUnif'> Drop uninformative categorical varibles</a>\n",
    "22. <a href='#dropMissing'>Drop variables with too many missing values</a>\n",
    "23. <a href='#encodeCat'>Encode Categorical Variables</a>\n",
    "24. <a href='#encodeCat1'>Encode Network Domain</a>\n",
    "25. <a href='#encodeCat2'>Encode Operating Systems</a>\n",
    "\n",
    "#### 3. <a href='#EDA'>Exploratory Data Analysis</a>\n",
    "\n",
    "#### 4. <a href='#ML'>Machine Learning to Predict Transactions</a>\n",
    "41. <a href='#rfEnum'>Random Forest with Enum Encoding</a>\n",
    "42. <a href='#gbmEnum'>GBM with Enum Encoding</a>\n",
    "43. <a href='#gbmTarget'>GBM with sort_by_response Encoding</a>\n",
    "44. <a href='#gbmTargetDev'>GBM with Target Encoding Channel/Device Analysis</a>\n",
    "\n",
    "\n",
    "#### 5. <a href='#visualization'>Visualization</a>\n",
    "51. <a href='#varimp'>Variable Importance Plot</a>\n",
    "52. <a href='#pdp'>Partial Dependency Plot</a>\n",
    "53. <a href='#pdp2dim'>Two Variable Partial Dependency Plot</a>\n",
    "54. <a href='#Treeplot'>Major Decision Trees Plot</a>\n",
    "\n",
    "#### 6. <a href='#Out-Of-Sample Walk Forward Testing'>Out-Of-Sample Walk Forward Testing</a>\n",
    "\n",
    "\n",
    "#### 7. <a href='#conclusion'>Conclusion</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import random\n",
    "import csv\n",
    "import numpy as np\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import seaborn\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "seaborn.set(rc={'figure.figsize':(15,12)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import subprocess\n",
    "from IPython.display import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def json_to_series(text):\n",
    "    keys, values = zip(*[item for item in json.loads(text).items()])\n",
    "    return pd.Series(values, index=keys)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='Sampling'></a>\n",
    "# 0.Sample 10% of data as training set\n",
    "<a href='#top'>back to top</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "filename = \"../data/train.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = sum(1 for line in open(filename,encoding=\"utf8\")) - 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Shuxinxu/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2717: DtypeWarning: Columns (3) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(filename,nrows=int(n/10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='clean'></a>\n",
    "# 1.Data Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='cleanID'></a>\n",
    "### 1.1 Clean ID\n",
    "<a href='#top'>back to top</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='cleanTotals'></a>\n",
    "### 1.2 Clean Totals\n",
    "<a href='#top'>back to top</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.concat([df, df['totals'].apply(json_to_series)], axis=1)\n",
    "\n",
    "df.drop(['totals'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def convert_int(df,cols):\n",
    "    for col in cols:\n",
    "        df[col] = df[col].map(lambda x: int(x) if not pd.isnull(x) else 0)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = convert_int(df,['pageviews','newVisits','visits','bounces','transactionRevenue'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['log_transactionRevenue'] = df['transactionRevenue'].map(lambda x:np.log(x+1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='cleanTS'></a>\n",
    "### 1.3 Clean Time Series\n",
    "<a href='#top'>back to top</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df[\"raw_visitStartTime\"] = df[\"visitStartTime\"].map(lambda x:datetime.utcfromtimestamp(x))\n",
    "\n",
    "df[\"visitStartTime\"] = df[\"visitStartTime\"].map(lambda x:datetime.utcfromtimestamp(x).hour)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.sort_values(by=['fullVisitorId','raw_visitStartTime'],inplace=True)\n",
    "\n",
    "df['nvisits'] = df.groupby(by='fullVisitorId')['fullVisitorId'].cumcount()+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_diff_time(x):\n",
    "    \n",
    "    return int(x.seconds//3600)+x.days*24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['pre_visitStartTime'] = df.groupby(by='fullVisitorId')['raw_visitStartTime'].shift(1)\n",
    "\n",
    "df['diff_lastVisitTime'] = (df['raw_visitStartTime']-df['pre_visitStartTime'])\n",
    "\n",
    "df['diff_lastVisitTime'] = df['diff_lastVisitTime'].map(lambda x: get_diff_time(x) if not pd.isnull(x) else np.NaN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['week'] = df['raw_visitStartTime'].map(lambda x: x.isocalendar()[1])\n",
    "\n",
    "df['day_of_week'] = df['raw_visitStartTime'].map(lambda x: x.isocalendar()[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.drop(['date'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='cleanLoc'></a>\n",
    "### 1.4 Clean Location\n",
    "<a href='#top'>back to top</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.concat([df, df['geoNetwork'].apply(json_to_series)], axis=1)\n",
    "\n",
    "df.drop(['geoNetwork'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='cleanDev'></a>\n",
    "### 1.5 Clean Device\n",
    "<a href='#top'>back to top</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.concat([df, df['device'].apply(json_to_series)], axis=1)\n",
    "\n",
    "df.drop(['device'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='cleanCust'></a>\n",
    "### 1.6 Clean Traffic Source\n",
    "<a href='#top'>back to top</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = pd.concat([df, df['trafficSource'].apply(json_to_series)], axis=1)\n",
    "\n",
    "df.drop(['trafficSource'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['adwordsClickInfo'] = df['adwordsClickInfo'].map(lambda x: str(x).replace(\"'\",\"\\\"\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([df, df['adwordsClickInfo'].apply(json_to_series)], axis=1)\n",
    "\n",
    "df.drop(['adwordsClickInfo'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='feature-eng'></a>\n",
    "# 2. Feature Cleaning\n",
    "<a href='#top'>back to top</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ID = [\"fullVisitorId\",\"visitId\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='dropUnif'></a>\n",
    "### 2.1 Drop uninformative categorical varibles\n",
    "<a href='#top'>back to top</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for col in df.columns:\n",
    "    cn = df[col].value_counts()\n",
    "    if cn.shape[0]==1:\n",
    "        df.drop(col,axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='dropMissing'></a>\n",
    "### 2.2 Drop variables with too many missing values\n",
    "<a href='#top'>back to top</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.replace(\"not available in demo dataset\",np.NaN,inplace=True)\n",
    "\n",
    "df.replace(\"NaN\",np.NaN,inplace=True)\n",
    "\n",
    "df.replace(\"(not set)\",np.NaN,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sessionQualityDim     0.53872\n",
       "timeOnSite            0.49974\n",
       "transactions          0.98998\n",
       "pre_visitStartTime    0.90097\n",
       "diff_lastVisitTime    0.90097\n",
       "region                0.57240\n",
       "metro                 0.77939\n",
       "city                  0.58195\n",
       "networkDomain         0.28537\n",
       "index                 0.20214\n",
       "value                 0.20214\n",
       "dtype: float64"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "na_df = np.sum(df.isna(),axis=0)/df.shape[0]\n",
    "na_df[na_df>0.1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.drop(['index',\"isMobile\",\"transactions\",\"metro\"],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='encodeCat'></a>\n",
    "### 2.3 Encode Categorical Variables\n",
    "<a href='#top'>back to top</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import category_encoders as ce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='encodeCat1'></a>\n",
    "### 2.3.1 Encode Categorical Variables -- networkDomain\n",
    "<a href='#top'>back to top</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.loc[df['networkDomain'].isna(),'networkDomain'] = 'unknown.unknown'\n",
    "\n",
    "df[\"raw_networkDomain\"] = df[\"networkDomain\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "min_sample_leaf = int(df.shape[0]*0.005)\n",
    "\n",
    "encoder = ce.TargetEncoder(cols=[\"networkDomain\"],min_samples_leaf=min_sample_leaf,smoothing=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TargetEncoder(cols=['networkDomain'], drop_invariant=False,\n",
       "       handle_unknown='impute', impute_missing=True, min_samples_leaf=500,\n",
       "       return_df=True, smoothing=1.0, verbose=0)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.fit(df.loc[:,~df.columns.isin([\"transactionRevenue\",\"log_transactionRevenue\"])], df[\"log_transactionRevenue\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_x = encoder.transform(df.loc[:,~df.columns.isin([\"transactionRevenue\",\"log_transactionRevenue\"])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['networkDomain'] = df_x['networkDomain']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cl='networkDomain'\n",
    "    \n",
    "_dict={}\n",
    "\n",
    "for k,g in df.groupby(by=cl):\n",
    "\n",
    "    if len(g['raw_'+cl].unique())<=10:\n",
    "        _dict[k] = list(g['raw_'+cl].unique())\n",
    "    else:\n",
    "        _dict[k] = ['Others']\n",
    "    \n",
    "networkDomain_dict = _dict "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='encodeCat2'></a>\n",
    "### 2.3.2 Encode Categorical Variables -- operating Systems\n",
    "<a href='#top'>back to top</a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['raw_operatingSystem'] = df['operatingSystem']\n",
    "df['raw_browser'] = df['browser']\n",
    "df['raw_region'] = df['region']\n",
    "df['raw_city'] = df['city']\n",
    "df['raw_country'] = df['country']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cols = [\"operatingSystem\",\"browser\",\"region\",\"city\",\"country\"]\n",
    "\n",
    "min_sample_leaf = int(df.shape[0]*0.005)\n",
    "\n",
    "encoder = ce.TargetEncoder(cols=cols,\n",
    "                           min_samples_leaf=min_sample_leaf,smoothing=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TargetEncoder(cols=['operatingSystem', 'browser', 'region', 'city', 'country'],\n",
       "       drop_invariant=False, handle_unknown='impute', impute_missing=True,\n",
       "       min_samples_leaf=500, return_df=True, smoothing=1.0, verbose=0)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.fit(df.loc[:,~df.columns.isin([\"transactionRevenue\",\"log_transactionRevenue\"])], df[\"log_transactionRevenue\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_x = encoder.transform(df.loc[:,~df.columns.isin([\"transactionRevenue\",\"log_transactionRevenue\"])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for col in cols:\n",
    "    df[col] = df_x[col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cl='operatingSystem'\n",
    "    \n",
    "_dict={}\n",
    "\n",
    "for k,g in df.groupby(by=cl):\n",
    "\n",
    "    if len(g['raw_'+cl].unique())<=10:\n",
    "        _dict[k] = list(g['raw_'+cl].unique())\n",
    "    else:\n",
    "        _dict[k] = ['Others']\n",
    "    \n",
    "operatingSystem_dict = _dict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cl='browser'\n",
    "    \n",
    "_dict={}\n",
    "\n",
    "for k,g in df.groupby(by=cl):\n",
    "\n",
    "    if len(g['raw_'+cl].unique())<=10:\n",
    "        _dict[k] = list(g['raw_'+cl].unique())\n",
    "    else:\n",
    "        _dict[k] = ['Others']\n",
    "    \n",
    "browser_dict = _dict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cl='region'\n",
    "    \n",
    "_dict={}\n",
    "\n",
    "for k,g in df.groupby(by=cl):\n",
    "\n",
    "    if len(g['raw_'+cl].unique())<=10:\n",
    "        _dict[k] = list(g['raw_'+cl].unique())\n",
    "    else:\n",
    "        _dict[k] = ['Others']\n",
    "    \n",
    "region_dict = _dict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cl='city'\n",
    "    \n",
    "_dict={}\n",
    "\n",
    "for k,g in df.groupby(by=cl):\n",
    "\n",
    "    if len(g['raw_'+cl].unique())<=10:\n",
    "        _dict[k] = list(g['raw_'+cl].unique())\n",
    "    else:\n",
    "        _dict[k] = ['Others']\n",
    "    \n",
    "city_dict = _dict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cl='country'\n",
    "    \n",
    "_dict={}\n",
    "\n",
    "for k,g in df.groupby(by=cl):\n",
    "\n",
    "    if len(g['raw_'+cl].unique())<=10:\n",
    "        _dict[k] = list(g['raw_'+cl].unique())\n",
    "    else:\n",
    "        _dict[k] = ['Others']\n",
    "    \n",
    "country_dict = _dict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.to_csv(\"train.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
